{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_processing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marytem/NSDUH_exploration/blob/master/data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "F6HbHZwgCIvg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data processing"
      ]
    },
    {
      "metadata": {
        "id": "JpSBpOfjFokn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "from mlxtend.plotting import plot_sequential_feature_selection\n",
        "from matplotlib import pyplot as plt\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSRFOpe4F0KQ",
        "colab_type": "code",
        "outputId": "12d86dca-9dd0-4ac0-8e8d-738f1f56909b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('prepared_data.csv')\n",
        "data.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (2283) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56897, 2432)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "q3mog4biPvMn",
        "colab_type": "code",
        "outputId": "02e53411-a8e2-4113-bf4f-df8e286f66a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>CIGEVER</th>\n",
              "      <th>CIGOFRSM</th>\n",
              "      <th>CIGWILYR</th>\n",
              "      <th>CIGTRY</th>\n",
              "      <th>CIGMFU</th>\n",
              "      <th>CIGREC</th>\n",
              "      <th>CIG30USE</th>\n",
              "      <th>CG30EST</th>\n",
              "      <th>CIG30AV</th>\n",
              "      <th>...</th>\n",
              "      <th>pnr_user</th>\n",
              "      <th>trq_user</th>\n",
              "      <th>stm_user</th>\n",
              "      <th>sed_user</th>\n",
              "      <th>cig_user</th>\n",
              "      <th>alc_user</th>\n",
              "      <th>mj_user</th>\n",
              "      <th>coc_user</th>\n",
              "      <th>crack_user</th>\n",
              "      <th>her_user</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>56897.00000</td>\n",
              "      <td>56897.000000</td>\n",
              "      <td>56886.000000</td>\n",
              "      <td>56885.000000</td>\n",
              "      <td>56531.000000</td>\n",
              "      <td>56341.000000</td>\n",
              "      <td>56897.000000</td>\n",
              "      <td>56790.000000</td>\n",
              "      <td>56861.000000</td>\n",
              "      <td>56850.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>56897.000000</td>\n",
              "      <td>56897.000000</td>\n",
              "      <td>56897.000000</td>\n",
              "      <td>56897.000000</td>\n",
              "      <td>56897.000000</td>\n",
              "      <td>56881.000000</td>\n",
              "      <td>56859.000000</td>\n",
              "      <td>56878.000000</td>\n",
              "      <td>56875.000000</td>\n",
              "      <td>56861.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>28448.00000</td>\n",
              "      <td>1.512751</td>\n",
              "      <td>78.090813</td>\n",
              "      <td>78.099077</td>\n",
              "      <td>519.117369</td>\n",
              "      <td>93.008857</td>\n",
              "      <td>47.982512</td>\n",
              "      <td>78.500229</td>\n",
              "      <td>92.979863</td>\n",
              "      <td>75.202375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049581</td>\n",
              "      <td>0.027734</td>\n",
              "      <td>0.030546</td>\n",
              "      <td>0.005695</td>\n",
              "      <td>0.437492</td>\n",
              "      <td>0.594961</td>\n",
              "      <td>0.179602</td>\n",
              "      <td>0.025247</td>\n",
              "      <td>0.003007</td>\n",
              "      <td>0.004397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>16424.89347</td>\n",
              "      <td>0.499842</td>\n",
              "      <td>39.399555</td>\n",
              "      <td>39.385467</td>\n",
              "      <td>487.314111</td>\n",
              "      <td>12.930240</td>\n",
              "      <td>44.156738</td>\n",
              "      <td>28.116961</td>\n",
              "      <td>4.323097</td>\n",
              "      <td>34.456714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.217079</td>\n",
              "      <td>0.164212</td>\n",
              "      <td>0.172087</td>\n",
              "      <td>0.075247</td>\n",
              "      <td>0.496082</td>\n",
              "      <td>0.490904</td>\n",
              "      <td>0.383859</td>\n",
              "      <td>0.238959</td>\n",
              "      <td>0.054750</td>\n",
              "      <td>0.066162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>14224.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28448.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>991.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>42672.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>991.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>56896.00000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>991.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 2431 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0       CIGEVER      CIGOFRSM      CIGWILYR        CIGTRY  \\\n",
              "count  56897.00000  56897.000000  56886.000000  56885.000000  56531.000000   \n",
              "mean   28448.00000      1.512751     78.090813     78.099077    519.117369   \n",
              "std    16424.89347      0.499842     39.399555     39.385467    487.314111   \n",
              "min        0.00000      1.000000      1.000000      1.000000      1.000000   \n",
              "25%    14224.00000      1.000000     99.000000     99.000000     16.000000   \n",
              "50%    28448.00000      2.000000     99.000000     99.000000    991.000000   \n",
              "75%    42672.00000      2.000000     99.000000     99.000000    991.000000   \n",
              "max    56896.00000      2.000000     99.000000     99.000000    991.000000   \n",
              "\n",
              "             CIGMFU        CIGREC      CIG30USE       CG30EST       CIG30AV  \\\n",
              "count  56341.000000  56897.000000  56790.000000  56861.000000  56850.000000   \n",
              "mean      93.008857     47.982512     78.500229     92.979863     75.202375   \n",
              "std       12.930240     44.156738     28.116961      4.323097     34.456714   \n",
              "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "25%       91.000000      3.000000     91.000000     91.000000     91.000000   \n",
              "50%       91.000000     91.000000     91.000000     91.000000     91.000000   \n",
              "75%       99.000000     91.000000     93.000000     93.000000     93.000000   \n",
              "max       99.000000     91.000000     93.000000     99.000000     93.000000   \n",
              "\n",
              "           ...           pnr_user      trq_user      stm_user      sed_user  \\\n",
              "count      ...       56897.000000  56897.000000  56897.000000  56897.000000   \n",
              "mean       ...           0.049581      0.027734      0.030546      0.005695   \n",
              "std        ...           0.217079      0.164212      0.172087      0.075247   \n",
              "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
              "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
              "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
              "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
              "max        ...           1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "           cig_user      alc_user       mj_user      coc_user    crack_user  \\\n",
              "count  56897.000000  56881.000000  56859.000000  56878.000000  56875.000000   \n",
              "mean       0.437492      0.594961      0.179602      0.025247      0.003007   \n",
              "std        0.496082      0.490904      0.383859      0.238959      0.054750   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "75%        1.000000      1.000000      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000     12.000000      1.000000   \n",
              "\n",
              "           her_user  \n",
              "count  56861.000000  \n",
              "mean       0.004397  \n",
              "std        0.066162  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        0.000000  \n",
              "max        1.000000  \n",
              "\n",
              "[8 rows x 2431 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "SHhpfESQFai0",
        "colab_type": "code",
        "outputId": "713d46a6-78b4-45d7-a690-a1cd3b5c4457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>CIGEVER</th>\n",
              "      <th>CIGOFRSM</th>\n",
              "      <th>CIGWILYR</th>\n",
              "      <th>CIGTRY</th>\n",
              "      <th>CIGMFU</th>\n",
              "      <th>CIGREC</th>\n",
              "      <th>CIG30USE</th>\n",
              "      <th>CG30EST</th>\n",
              "      <th>CIG30AV</th>\n",
              "      <th>...</th>\n",
              "      <th>pnr_user</th>\n",
              "      <th>trq_user</th>\n",
              "      <th>stm_user</th>\n",
              "      <th>sed_user</th>\n",
              "      <th>cig_user</th>\n",
              "      <th>alc_user</th>\n",
              "      <th>mj_user</th>\n",
              "      <th>coc_user</th>\n",
              "      <th>crack_user</th>\n",
              "      <th>her_user</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>4</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>991.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>91.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>99.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>99.0</td>\n",
              "      <td>4</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2432 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  CIGEVER  CIGOFRSM  CIGWILYR  CIGTRY  CIGMFU  CIGREC  CIG30USE  \\\n",
              "0           0        1      99.0      99.0    16.0    99.0       4      93.0   \n",
              "1           1        1      99.0      99.0    15.0    99.0       1       7.0   \n",
              "2           2        1      99.0      99.0    26.0    99.0       1       7.0   \n",
              "3           3        2       4.0       4.0   991.0    91.0      91      91.0   \n",
              "4           4        1      99.0      99.0     5.0    99.0       4      93.0   \n",
              "\n",
              "   CG30EST  CIG30AV    ...     pnr_user  trq_user  stm_user  sed_user  \\\n",
              "0     93.0     93.0    ...            0         0         0         0   \n",
              "1     99.0      2.0    ...            1         1         1         1   \n",
              "2     99.0      4.0    ...            0         0         0         0   \n",
              "3     91.0     91.0    ...            0         0         0         0   \n",
              "4     93.0     93.0    ...            0         0         0         0   \n",
              "\n",
              "   cig_user  alc_user  mj_user  coc_user  crack_user  her_user  \n",
              "0         1       1.0      0.0       0.0         0.0       0.0  \n",
              "1         1       1.0      1.0       1.0         1.0       1.0  \n",
              "2         1       0.0      0.0       0.0         0.0       0.0  \n",
              "3         0       0.0      0.0       0.0         0.0       0.0  \n",
              "4         1       1.0      0.0       0.0         0.0       0.0  \n",
              "\n",
              "[5 rows x 2432 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "FnS5vB_XIp0j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Dealing with missing values\n",
        "Due to the cpecifics of the survey data I wanted to use 2 types of missing value imputation. For all drug-related columns I used global most common substitution, because thte data is categorical and because most peope do not use drugs. The rest columns with missing values were supposed to be imputed by the KNN model.\n",
        "\n",
        "__BUT__\n",
        "\n",
        "Unfortunately i can not afford to run it on so much data, so I used mode imputation in all dataset.\n",
        "\n",
        "Columns with more than 20% of missing values are droped cince mode MVs imputation would influence data too much, and there are relatively not much of such columns and too much columns in a dataset anyway."
      ]
    },
    {
      "metadata": {
        "id": "YHpMynnhdr3d",
        "colab_type": "code",
        "outputId": "40efd4ca-912b-40da-d69b-ac36287e01b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "none_percs = data[data.columns[data.isnull().any()]].isnull().mean() * 100\n",
        "nearly_empty_cols = [none_percs[none_percs == perc].index[0] for perc in none_percs if perc>20]\n",
        "len(nearly_empty_cols)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "357"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "01XVRuBr6-DJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.drop(nearly_empty_cols, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_pFxmQrdGc8",
        "colab_type": "code",
        "outputId": "47374d4a-a2fd-4e7e-a801-3243948b7117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# number of cols with MVs, total part of MVs\n",
        "len(data.columns[data.isnull().any()]),  data.isnull().values.ravel().sum()/(data.shape[0]*data.shape[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1638, 0.059268863420781505)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "TZ3SMeADDkJa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Data Separation\n",
        "I want to predict if a person uses particular drug using answers to the specific-drug-unrelated questions in the survey and then using questions not connected to any drug usage. For that I need to separate all drug related variables from general data.\n",
        "\n",
        "##### Prefixes in variables-questions used for every type of drug:"
      ]
    },
    {
      "metadata": {
        "id": "eGFRjSer9in0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "halucinogens = ['LSD', 'PCP','PEYOTE','MESC','PSILCY','ECST','KET','DMTAMTFXY','SALVIADIV']\n",
        "inhalants = ['AMYLNIT', 'CLEFLU', 'GAS', 'GLUE', 'ETHER', 'SOLVENT', 'LGAS', 'NITOXID',\n",
        "             'FELTMARKR', 'SPPAINT', 'AIRDUSTER', 'OTHAEROS']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HX7QdsqqDw_n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prefixes = {}\n",
        "prefixes['tobacco'] = 'CIG', 'CGR', 'CI3', 'PIP', 'SMK', 'TOB', 'CD'\n",
        "prefixes['alcohol'] = ('AL')\n",
        "prefixes['marijuana'] = 'MJ', 'MR'\n",
        "prefixes['cocaine'] = 'COC', 'CC', 'CON'\n",
        "prefixes['crack'] = 'CRK', 'CR' \n",
        "prefixes['heroin'] = 'HER', 'HR', 'HEO'\n",
        "prefixes['hallucinogens'] = ['HAL']+halucinogens\n",
        "prefixes['inhalants'] = ['INH']+inhalants\n",
        "prefixes['methamphetamine'] = 'MET', 'ME'\n",
        "prefixes['pain relievers'] = 'PNR', 'OXC'\n",
        "prefixes['tranqualizers'] = ('TRQ')\n",
        "prefixes['stimulants'] = 'SED', 'PSY'\n",
        "prefixes['sedaives'] = ('STM')\n",
        "prefixes['special drugs'] = 'COLD', 'GH', 'OT'\n",
        "prefixes['general about drugs'] = ('GNN')\n",
        "prefixes['targets'] = ['hal_user', 'inh_user', 'meth_user', 'pnr_user', \n",
        "                       'trq_user', 'stm_user', 'sed_user', 'cig_user',\n",
        "                       'alc_user', 'mj_user', 'coc_user', 'crack_user', 'her_user']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mc5bYfHfDw7O",
        "colab_type": "code",
        "outputId": "e3f899b4-2c8a-4f4f-da4e-4368eeb62cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "drug_cols = []\n",
        "for drug in prefixes.keys():\n",
        "  drug_cols += [col for col in data.columns if col.startswith(tuple(prefixes[drug]))]\n",
        "len(drug_cols)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "ufclcjngDw4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(missing_values = np.nan, strategy = 'most_frequent')\n",
        "data[data.columns] = imputer.fit_transform(data[data.columns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o2ChPelvm0-x",
        "colab_type": "code",
        "outputId": "b93db515-e2c2-4e2e-eea9-67457813b8e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data.isnull().values.ravel().sum(), data.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, (56897, 2222))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "V3FpATK2E1_K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.to_csv('mode_imputed.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "43oVBTTrCs4v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Dealing with noise"
      ]
    },
    {
      "metadata": {
        "id": "4vQKSYzNDSCO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## IMPORTANT NOTE:\n",
        " From here on I will preform every step of dataprocessing for one type of drugs (__Marijuana__) with explanations why i choose certain mehod.\n",
        " \n",
        " In this project I need to do it for 13 drug types, to generate datasets for every drug, which will be done in other noebook."
      ]
    },
    {
      "metadata": {
        "id": "34u4Jqu4fqVL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Data reduction\n",
        "i used Factor Analysis as it not only reduces dimentions but may also increase accuracy if a proper number of factors will be selected."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BzH2QpUDkzPy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data.drop([col for col in data.columns if col.startswith(prefixes['marijuana'])], axis=1))\n",
        "train_Ys = train[prefixes['targets']]\n",
        "train.drop(prefixes['targets'], axis=1, inplace=True)\n",
        "test_Ys = test[prefixes['targets']]\n",
        "test.drop(prefixes['targets'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TPqpvHiogE_j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fa = FactorAnalysis(n_components=100)\n",
        "train = fa.fit_transform(train.values)\n",
        "test = fa.transform(test.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nBGL_kk7qx80",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d878bdf2-6f88-4bac-cf54-cde3bbecc9a0"
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(C=10, solver='lbfgs', max_iter = 1000).fit(train, train_Ys['mj_user'])\n",
        "accuracy = accuracy_score(test_Ys['mj_user'], clf.predict(test))\n",
        "accuracy"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9979613356766257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "gwjAgA-eb4Rn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Feature selection \n",
        "Since I already decreased dimenionality i can use effective enough and reasonably time consuming feaure selection method - Stepwise Forward Selection."
      ]
    },
    {
      "metadata": {
        "id": "9-mPIVTTgE1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(C=10, solver='lbfgs', max_iter = 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TvyRjZoigEoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3770
        },
        "outputId": "48817a10-32cb-44e5-fe60-c7bf61b3f191"
      },
      "cell_type": "code",
      "source": [
        "selector = SFS(clf, forward=True, verbose=2, scoring='accuracy', cv=0, n_jobs=-1, k_features=100).fit(train, train_Ys['mj_user'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.1s finished\n",
            "\n",
            "[2019-01-10 22:24:07] Features: 1/100 -- score: 0.9305868016497938[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  99 out of  99 | elapsed:    8.2s finished\n",
            "\n",
            "[2019-01-10 22:24:16] Features: 2/100 -- score: 0.9595753655793026[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done  98 out of  98 | elapsed:    9.1s finished\n",
            "\n",
            "[2019-01-10 22:24:25] Features: 3/100 -- score: 0.9693710161229846[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=-1)]: Done  94 out of  97 | elapsed:    9.5s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  97 out of  97 | elapsed:    9.7s finished\n",
            "\n",
            "[2019-01-10 22:24:34] Features: 4/100 -- score: 0.9764013873265842[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:   11.1s finished\n",
            "\n",
            "[2019-01-10 22:24:45] Features: 5/100 -- score: 0.983830146231721[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.0s\n",
            "[Parallel(n_jobs=-1)]: Done  95 out of  95 | elapsed:   12.6s finished\n",
            "\n",
            "[2019-01-10 22:24:58] Features: 6/100 -- score: 0.9883998875140607[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done  94 out of  94 | elapsed:   13.2s finished\n",
            "\n",
            "[2019-01-10 22:25:11] Features: 7/100 -- score: 0.9907667791526059[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done  93 out of  93 | elapsed:   13.2s finished\n",
            "\n",
            "[2019-01-10 22:25:24] Features: 8/100 -- score: 0.9921728533933258[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    5.7s\n",
            "[Parallel(n_jobs=-1)]: Done  92 out of  92 | elapsed:   14.2s finished\n",
            "\n",
            "[2019-01-10 22:25:39] Features: 9/100 -- score: 0.9937429696287964[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done  91 out of  91 | elapsed:   15.0s finished\n",
            "\n",
            "[2019-01-10 22:25:54] Features: 10/100 -- score: 0.994539745031871[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   14.9s finished\n",
            "\n",
            "[2019-01-10 22:26:09] Features: 11/100 -- score: 0.995031871016123[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=-1)]: Done  89 out of  89 | elapsed:   16.6s finished\n",
            "\n",
            "[2019-01-10 22:26:25] Features: 12/100 -- score: 0.9956880389951256[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.2s\n",
            "[Parallel(n_jobs=-1)]: Done  88 out of  88 | elapsed:   16.6s finished\n",
            "\n",
            "[2019-01-10 22:26:42] Features: 13/100 -- score: 0.9961332958380202[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.1s\n",
            "[Parallel(n_jobs=-1)]: Done  87 out of  87 | elapsed:   16.6s finished\n",
            "\n",
            "[2019-01-10 22:26:59] Features: 14/100 -- score: 0.996367641544807[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=-1)]: Done  86 out of  86 | elapsed:   18.4s finished\n",
            "\n",
            "[2019-01-10 22:27:17] Features: 15/100 -- score: 0.9965551181102362[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.3s\n",
            "[Parallel(n_jobs=-1)]: Done  85 out of  85 | elapsed:   16.4s finished\n",
            "\n",
            "[2019-01-10 22:27:33] Features: 16/100 -- score: 0.9967191601049868[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=-1)]: Done  84 out of  84 | elapsed:   17.2s finished\n",
            "\n",
            "[2019-01-10 22:27:50] Features: 17/100 -- score: 0.9969300712410949[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done  83 out of  83 | elapsed:   17.4s finished\n",
            "\n",
            "[2019-01-10 22:28:08] Features: 18/100 -- score: 0.9970238095238095[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=-1)]: Done  82 out of  82 | elapsed:   19.2s finished\n",
            "\n",
            "[2019-01-10 22:28:27] Features: 19/100 -- score: 0.9970706786651669[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   19.1s finished\n",
            "\n",
            "[2019-01-10 22:28:46] Features: 20/100 -- score: 0.9971644169478815[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:   18.8s finished\n",
            "\n",
            "[2019-01-10 22:29:05] Features: 21/100 -- score: 0.9972347206599175[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    8.9s\n",
            "[Parallel(n_jobs=-1)]: Done  79 out of  79 | elapsed:   18.7s finished\n",
            "\n",
            "[2019-01-10 22:29:24] Features: 22/100 -- score: 0.9972815898012748[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.0s\n",
            "[Parallel(n_jobs=-1)]: Done  78 out of  78 | elapsed:   19.2s finished\n",
            "\n",
            "[2019-01-10 22:29:43] Features: 23/100 -- score: 0.9973284589426322[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    8.5s\n",
            "[Parallel(n_jobs=-1)]: Done  77 out of  77 | elapsed:   17.3s finished\n",
            "\n",
            "[2019-01-10 22:30:00] Features: 24/100 -- score: 0.9973518935133109[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.0s\n",
            "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:   18.3s finished\n",
            "\n",
            "[2019-01-10 22:30:19] Features: 25/100 -- score: 0.9973753280839895[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   18.8s finished\n",
            "\n",
            "[2019-01-10 22:30:37] Features: 26/100 -- score: 0.9973987626546682[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done  74 out of  74 | elapsed:   18.9s finished\n",
            "\n",
            "[2019-01-10 22:30:56] Features: 27/100 -- score: 0.9973987626546682[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.3s\n",
            "[Parallel(n_jobs=-1)]: Done  73 out of  73 | elapsed:   17.9s finished\n",
            "\n",
            "[2019-01-10 22:31:14] Features: 28/100 -- score: 0.9973987626546682[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed:   18.2s finished\n",
            "\n",
            "[2019-01-10 22:31:32] Features: 29/100 -- score: 0.9973987626546682[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done  71 out of  71 | elapsed:   19.5s finished\n",
            "\n",
            "[2019-01-10 22:31:52] Features: 30/100 -- score: 0.9973987626546682[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done  70 out of  70 | elapsed:   18.2s finished\n",
            "\n",
            "[2019-01-10 22:32:10] Features: 31/100 -- score: 0.9974221972253469[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=-1)]: Done  69 out of  69 | elapsed:   17.7s finished\n",
            "\n",
            "[2019-01-10 22:32:28] Features: 32/100 -- score: 0.9974221972253469[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=-1)]: Done  68 out of  68 | elapsed:   17.7s finished\n",
            "\n",
            "[2019-01-10 22:32:46] Features: 33/100 -- score: 0.9974456317960255[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.2s\n",
            "[Parallel(n_jobs=-1)]: Done  67 out of  67 | elapsed:   18.0s finished\n",
            "\n",
            "[2019-01-10 22:33:03] Features: 34/100 -- score: 0.9974690663667042[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.3s\n",
            "[Parallel(n_jobs=-1)]: Done  66 out of  66 | elapsed:   17.9s finished\n",
            "\n",
            "[2019-01-10 22:33:21] Features: 35/100 -- score: 0.9974690663667042[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.4s\n",
            "[Parallel(n_jobs=-1)]: Done  65 out of  65 | elapsed:   18.1s finished\n",
            "\n",
            "[2019-01-10 22:33:39] Features: 36/100 -- score: 0.9975159355080615[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.7s\n",
            "[Parallel(n_jobs=-1)]: Done  64 out of  64 | elapsed:   18.0s finished\n",
            "\n",
            "[2019-01-10 22:33:57] Features: 37/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.8s\n",
            "[Parallel(n_jobs=-1)]: Done  63 out of  63 | elapsed:   19.5s finished\n",
            "\n",
            "[2019-01-10 22:34:17] Features: 38/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done  62 out of  62 | elapsed:   17.8s finished\n",
            "\n",
            "[2019-01-10 22:34:35] Features: 39/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.5s\n",
            "[Parallel(n_jobs=-1)]: Done  61 out of  61 | elapsed:   17.2s finished\n",
            "\n",
            "[2019-01-10 22:34:52] Features: 40/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   17.3s finished\n",
            "\n",
            "[2019-01-10 22:35:09] Features: 41/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done  59 out of  59 | elapsed:   17.6s finished\n",
            "\n",
            "[2019-01-10 22:35:27] Features: 42/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=-1)]: Done  58 out of  58 | elapsed:   17.2s finished\n",
            "\n",
            "[2019-01-10 22:35:44] Features: 43/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.5s\n",
            "[Parallel(n_jobs=-1)]: Done  57 out of  57 | elapsed:   17.4s finished\n",
            "\n",
            "[2019-01-10 22:36:02] Features: 44/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:   18.2s finished\n",
            "\n",
            "[2019-01-10 22:36:20] Features: 45/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.9s\n",
            "[Parallel(n_jobs=-1)]: Done  55 out of  55 | elapsed:   17.3s finished\n",
            "\n",
            "[2019-01-10 22:36:37] Features: 46/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:   16.3s finished\n",
            "\n",
            "[2019-01-10 22:36:53] Features: 47/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=-1)]: Done  53 out of  53 | elapsed:   15.7s finished\n",
            "\n",
            "[2019-01-10 22:37:09] Features: 48/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   12.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 out of  52 | elapsed:   17.3s finished\n",
            "\n",
            "[2019-01-10 22:37:27] Features: 49/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=-1)]: Done  51 out of  51 | elapsed:   16.4s finished\n",
            "\n",
            "[2019-01-10 22:37:43] Features: 50/100 -- score: 0.9975393700787402[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   12.2s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   16.1s finished\n",
            "\n",
            "[2019-01-10 22:37:59] Features: 51/100 -- score: 0.9975159355080615[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "\n",
            "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aATOzBtNTFlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "b536532d-29ae-47dc-ed3c-65a83c413254"
      },
      "cell_type": "code",
      "source": [
        "fig = plot_sequential_feature_selection(selector.get_metric_dict(), kind='std_dev')\n",
        "\n",
        "plt.ylim([0.94, 1])\n",
        "plt.title('Sequential forward Selection')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  keepdims=keepdims)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2b7f82f7b8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Gi1XunC0qbG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see from both graph and output of training the optimal number of features is 25."
      ]
    },
    {
      "metadata": {
        "id": "kkAwFJea6-XV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bc45974-3a6d-4bbd-8f5e-a8489beb91ef"
      },
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14225, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "_vQAYkxo69_a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NkXL5RtQrfr_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "needed_features = selector.subsets_[25]['feature_idx']\n",
        "train = train[:, needed_features]\n",
        "test = test[:, needed_features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oj7gB2gTE252",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "influence of RSK\n",
        "\n",
        "special drugs\n",
        "\n",
        "needle any\n",
        "\n",
        "correlatin in fa to tune num of facs\n",
        "\n",
        "ldocs percent"
      ]
    }
  ]
}